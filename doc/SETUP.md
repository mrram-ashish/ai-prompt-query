### Setting up Large Language model(LLM) in Local
First need access to an Ollama instance.(Ollama is free)
Download Ollama in local machine:
https://docs.spring.io/spring-ai/reference/api/chat/ollama-chat.html

* Pull Ai-model for Ollama/Library
https://ollama.com/library

* I tried using Mistral Model:
https://ollama.com/library/mistral

* Validate if ollama is running: http://localhost:11434/